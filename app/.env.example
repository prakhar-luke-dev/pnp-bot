BOT_NAME = "Luke"

## for FastAPI app
PORT = 8001
HOST = "0.0.0.0"

## Deepinfra token as LLM inference provider
DEEPINFRA_API_TOKEN = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
DEEPINFRA_BASE_URL = "https://api.deepinfra.com/v1/openai"


## Vector DB for RAG
PINECONE_API_KEY = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
PINECONE_INDEX_NAME = new_index1


## Random key to access log in browser
LOG_KEY = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"


## Bugsnag config
BUGSNAG_API = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

## Postgres for memory storage (without it `MemorySaver()` will be used but i'll be stored in RAM)
POSTGRES_DB = your-db-name
POSTGRES_USER = your-user-name
POSTGRES_PASSWORD = your-password
PSQL_CONTAINER_NAME = postgres-container-name
PSQL_CONTAINER_PORT = 1234


## Optional : For Tracing in production
LANGFUSE_SECRET_KEY = "your-langfuse-secret-key"
LANGFUSE_PUBLIC_KEY = "your-langfuse-public-key"
LANGFUSE_HOST = "your-langfuse-url"




## API Auth
SECRET_KEY ="xxxxxxxxxx-yyyyyyyyy;zzzzzz"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES  = 120
REFRESH_TOKEN_EXPIRE_DAYS = 1

## SQL AGENT REQUIREMENTS
DB_HOST = "localhost"
DB_USER = "postgres"
DB_PASS = "hestabit"
DB_NAME = "test"
DB_PORT = "5432"